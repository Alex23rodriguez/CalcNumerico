{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from IPython.display import Latex\n",
    "import latexStrings as ls\n",
    "import numpy as np\n",
    "import scipy.linalg as linear\n",
    "import eigenvalues as ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la matriz A como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\[ \n",
       "A = \n",
       "\\begin{pmatrix} \n",
       "1 & -4 & -6 \\\\ \n",
       "-12 & -8 & -6 \\\\ \n",
       "11 & 10 & 10 \\\\ \n",
       "\\end{pmatrix}\n",
       " \\]"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,-4,-6],[-12,-8,-6],[11,10,10]])\n",
    "\n",
    "Latex(ls.latexMatrix(A,'A'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que $A$ es invertible pues $det(A)=-44\\neq0$ y por lo tanto $A^{-1}$ existe, permitiendo hacer el metodo de la potencia inversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos los eigenvalores y eigenvectores de $A$ utilizando _scipy.linalg_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\[ \n",
       " \\vec{\\lambda} = \n",
       "\\begin{pmatrix} \n",
       "2.881554 \\\\ \n",
       "2.881554 \\\\ \n",
       "-2.763109 \\\\ \n",
       "\\end{pmatrix}\n",
       " \\]\\[ \n",
       "V = \n",
       "\\begin{pmatrix} \n",
       "-0.386685 & -0.386685 & -0.063674 \\\\ \n",
       "0.685967 & 0.685967 & 0.811470 \\\\ \n",
       "-0.470695 & -0.470695 & -0.580915 \\\\ \n",
       "\\end{pmatrix}\n",
       " \\]"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[eigenvalues,eigenvectors]=linear.eig(A)\n",
    "[eigenvalues,eigenvectors]=ev.pairSort(eigenvalues,eigenvectors)\n",
    "\n",
    "Latex(ls.latexVector(eigenvalues,'\\lambda',form='%f') + ls.latexMatrix(eigenvectors,'V',form='%f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $A$ tiene eigenvalores {$\\lambda_1,\\lambda_2,\\lambda_3$}, entonces sabemos que $A^{-1}$ tiene eigenvalores {$\\frac{1}{\\lambda_1},\\frac{1}{\\lambda_2},\\frac{1}{\\lambda_3}$}. Entonces, observamos que: \n",
    "$$|\\frac{1}{-2.763109}|>|\\frac{1}{2.881554}| \\Rightarrow |\\frac{1}{\\lambda_3}|>|\\frac{1}{\\lambda_2}|=|\\frac{1}{\\lambda_1}|\\Rightarrow |\\frac{1}{\\lambda_3}|>|\\frac{1}{\\lambda_i}|\\quad\\forall i\\neq 3$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto existe el eigenvalor dominante $\\frac{1}{\\lambda_3}=\\frac{1}{-2.763109}$ de $A^{-1}$ y el método de la potencia inversa debería, con un vector inicial $\\vec{q}_0$ apropiado, converge a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\[ \n",
       " \\vec{v_3} = \n",
       "\\begin{pmatrix} \n",
       "-0.063674 \\\\ \n",
       "0.811470 \\\\ \n",
       "-0.580915 \\\\ \n",
       "\\end{pmatrix}\n",
       " \\]$\\lambda_3$ = -2.763108507220637"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v3 = np.array(eigenvectors[:,2])\n",
    "Latex(ls.latexVector(v3,'v_3',form=\"%f\") + '$\\lambda_3$ = '+str(eigenvalues[2].real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tomemos $\\vec{q}_0$ que cumpla la segunda hipotesis. En este caso vemos que $\\vec{q}_0=(1,1,1)$ lo cumple, pues al no ser ortogonal a ninguno de los eigenvectores, los coeficientes de su combinacion lineal son todos distintos de 0.\n",
    "Comprobemos que el metodo sirve coriendo la función inversePower con $A$ y $\\vec{q}_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Numero de iteraciones: 45\\[ \n",
       " \\vec{w_3} = \n",
       "\\begin{pmatrix} \n",
       "0.063674 \\\\ \n",
       "-0.811470 \\\\ \n",
       "0.580915 \\\\ \n",
       "\\end{pmatrix}\n",
       " \\]$\\sigma_3$ = -2.7631087076453653"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = np.array([1,1,1])\n",
    "[w,l,i] = ev.inversePower(A,q)\n",
    "Latex(\"Numero de iteraciones: \"+ str(i) + ls.latexVector(w,'w_3',form=\"%f\") + '$\\sigma_3$ = '+str(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el método si funciona pues aproxima de manera correcta el eigenpar $(\\overrightarrow{v_3},\\lambda_3)$ siendo $\\lambda_3=-2.7663109$ el eigenvalor con norma más pequeña y su eigenvector normal asociado "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
